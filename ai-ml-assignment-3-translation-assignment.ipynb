{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers nltk spacy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import MarianTokenizer, MarianMTModel\nimport nltk\nimport spacy\nfrom nltk import pos_tag\nnltk.download('punkt')\nnlp = spacy.load(\"en_core_web_md\")\n\n# Load the pre-trained Marian model and tokenizer for English-to-Hindi translation\ntranslation_model_name = \"Helsinki-NLP/opus-mt-en-hi\"\ntokenizer = MarianTokenizer.from_pretrained(translation_model_name)\ntranslation_model = MarianMTModel.from_pretrained(translation_model_name)\n\nmodel_name_hi_en = \"Helsinki-NLP/opus-mt-hi-en\"\ntokenizer_hi_en = MarianTokenizer.from_pretrained(model_name_hi_en)\nmodel_hi_en = MarianMTModel.from_pretrained(model_name_hi_en)\n\n# Function to translate English sentence to Hindi\ndef translate_to_hindi(english_sentence):\n    inputs = tokenizer(english_sentence, return_tensors=\"pt\")\n    translated = translation_model.generate(**inputs)\n    translated_sentence = tokenizer.decode(translated[0], skip_special_tokens=True)\n    return translated_sentence\n\ndef translate_to_english(hindi_sentence):\n    inputs = tokenizer_hi_en(hindi_sentence, return_tensors=\"pt\")\n    translated = model_hi_en.generate(**inputs)\n    translated_sentence = tokenizer_hi_en.decode(translated[0], skip_special_tokens=True)\n    return translated_sentence\n\ndef extract_and_translate_nouns(english_sentence):\n    # Tokenize the English sentence\n    english_words = nltk.word_tokenize(english_sentence)\n    \n    # Perform POS tagging to identify nouns\n    pos_tags = pos_tag(english_words)\n    \n    noun_translations = {}\n    \n    for word, pos in pos_tags:\n        if pos in [\"NN\",\"NNP\",\"NNS\"]:  # Check if the word is a noun\n            lemmatized_word = nlp(word)[0].lemma_\n            noun_translations[lemmatized_word] = word.lower()\n    \n    return noun_translations\n\n# Replace specific Hindi words with their English counterparts\ndef replace_hindi_with_english(hindi_sentence, noun_translations):\n    hindi_words = hindi_sentence.split()\n    for i in range(len(hindi_words)):\n        english_word = translate_to_english(hindi_words[i]).lower()\n        lemmatized = nlp(english_word)[0].lemma_\n        \n        if lemmatized in noun_translations:\n            hindi_words[i] = noun_translations[lemmatized]\n    \n    final_sentence = ' '.join(hindi_words)\n    \n    return final_sentence\n\n# Sentence 1\nenglish_sentence = \"Definitely share your feedback in the comment section\"\nhindi_translation = translate_to_hindi(english_sentence)\nnoun_translations = extract_and_translate_nouns(english_sentence)\nfinal_hindi_sentence = replace_hindi_with_english(hindi_translation, noun_translations)\n\nprint(\"\\nOriginal English sentence 1: \", english_sentence)\nprint(\"Final Hinglish sentence 1: \", final_hindi_sentence, \"\\n\")\n\n# Sentence 2\nenglish_sentence = \"So even if it's a big video, I will clearly mention all the products\"\nhindi_translation = translate_to_hindi(english_sentence)\nnoun_translations = extract_and_translate_nouns(english_sentence)\nfinal_hindi_sentence = replace_hindi_with_english(hindi_translation, noun_translations)\n\nprint(\"\\nOriginal English sentence 2: \", english_sentence)\nprint(\"Final Hinglish sentence 2: \", final_hindi_sentence, \"\\n\")\n\n# Sentence 3\nenglish_sentence = \"I was waiting for my bag\"\nhindi_translation = translate_to_hindi(english_sentence)\nnoun_translations = extract_and_translate_nouns(english_sentence)\nfinal_hindi_sentence = replace_hindi_with_english(hindi_translation, noun_translations)\n\nprint(\"\\nOriginal English sentence 3: \", english_sentence)\nprint(\"Final Hinglish sentence 3: \", final_hindi_sentence,\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-09-01T17:22:20.899987Z","iopub.execute_input":"2023-09-01T17:22:20.900395Z","iopub.status.idle":"2023-09-01T17:24:00.029578Z","shell.execute_reply.started":"2023-09-01T17:22:20.900363Z","shell.execute_reply":"2023-09-01T17:24:00.028543Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n\nOriginal English sentence 1:  Definitely share your feedback in the comment section\nFinal Hinglish sentence 1:  comment खण्ड में आपकी प्रतिक्रिया को निश्‍चित ही share करें \n\n\nOriginal English sentence 2:  So even if it's a big video, I will clearly mention all the products\nFinal Hinglish sentence 2:  तो यह एक बड़ा video है, तो भी मैं स्पष्ट रूप से सभी products का उल्लेख करेंगे \n\n\nOriginal English sentence 3:  I was waiting for my bag\nFinal Hinglish sentence 3:  मैं अपने बैग के लिए इंतजार कर रहा था \n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}